{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "walker2d_colab_training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcNLIOS5SjGgcu6PbD9CWQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-tikh/MADE-Practical-RL-homework-2021/blob/main/hw02_walker2d/walker2d_colab_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TO0lxwH9xeq",
        "outputId": "94356e24-9c28-4bea-a3fa-6a5a4620bdea"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 15 10:06:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm5zTJt394CP",
        "outputId": "08a2e5a0-7371-40bb-954c-e7c16815079c"
      },
      "source": [
        "!pip install -q pybullet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 89.3 MB 76 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os3Vs4AS97ML",
        "outputId": "99ae5546-8fb8-4afb-e15f-207703459bba"
      },
      "source": [
        "!git clone https://github.com/alex-tikh/MADE-Practical-RL-homework-2021.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MADE-Practical-RL-homework-2021'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 110 (delta 51), reused 89 (delta 36), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 24.41 KiB | 8.13 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3UbXdI0-dyS",
        "outputId": "9944112b-4998-4114-c2eb-ae06b3678d27"
      },
      "source": [
        "%cd MADE-Practical-RL-homework-2021/hw02_walker2d/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MADE-Practical-RL-homework-2021/hw02_walker2d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsCUGKvC_NGr",
        "outputId": "b017f6de-d6c5-4223-ee74-66b3a134d073"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzdkKFnb-qrw",
        "outputId": "51d04af5-dc4e-45d3-f614-3dfced46d878"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent.py  README.md  train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okw-z7UP-r_L"
      },
      "source": [
        "import train"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA6SHGtlC7W9"
      },
      "source": [
        "train.BATCH_SIZE = 512\n",
        "train.HIDDEN_DIM = 256\n",
        "\n",
        "train.TRANSITIONS = 15000"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJGZkm4l-2I_",
        "outputId": "d07f00fc-2db5-4c5c-8241-12e9af8baff1"
      },
      "source": [
        "train.main()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 10, Reward mean: 44.69967294714269, Reward std: 15.376477544656321, Episodes: 1003, Steps: 20619\n",
            "Step: 20, Reward mean: 65.8205303667573, Reward std: 12.060177933033241, Episodes: 1264, Steps: 41610\n",
            "Step: 30, Reward mean: 62.443159615050526, Reward std: 9.757060028780263, Episodes: 1482, Steps: 62553\n",
            "Step: 40, Reward mean: 84.22869446557596, Reward std: 6.748002039061556, Episodes: 1699, Steps: 83600\n",
            "Step: 50, Reward mean: 65.43859975332103, Reward std: 7.0249127919687115, Episodes: 1885, Steps: 105015\n",
            "Step: 60, Reward mean: 94.75803585949527, Reward std: 26.26196840262366, Episodes: 2069, Steps: 126039\n",
            "Step: 70, Reward mean: 120.3518442355795, Reward std: 41.90965255897922, Episodes: 2235, Steps: 147142\n",
            "Step: 80, Reward mean: 59.64455407055881, Reward std: 21.506323879357858, Episodes: 2416, Steps: 168227\n",
            "Step: 90, Reward mean: 92.99600213788887, Reward std: 38.73581060560578, Episodes: 2590, Steps: 189429\n",
            "Step: 100, Reward mean: 83.8896546343944, Reward std: 11.534216677224354, Episodes: 2729, Steps: 210610\n",
            "Step: 110, Reward mean: 82.78059786135768, Reward std: 28.880908471935065, Episodes: 2875, Steps: 231925\n",
            "Step: 120, Reward mean: 122.9797243966797, Reward std: 71.34201043398741, Episodes: 2997, Steps: 253685\n",
            "Step: 130, Reward mean: 431.6510022203459, Reward std: 223.090931296194, Episodes: 3052, Steps: 278181\n",
            "Step: 140, Reward mean: 191.95416121412467, Reward std: 80.71845930078524, Episodes: 3103, Steps: 305692\n",
            "Step: 150, Reward mean: 263.141119042141, Reward std: 247.92949059922447, Episodes: 3160, Steps: 330931\n",
            "Step: 160, Reward mean: 227.10575395507735, Reward std: 190.62992221114368, Episodes: 3209, Steps: 355336\n",
            "Step: 170, Reward mean: 587.9492025304648, Reward std: 260.1530840597458, Episodes: 3272, Steps: 382576\n",
            "Step: 180, Reward mean: 551.287968284278, Reward std: 256.0420287405205, Episodes: 3319, Steps: 408345\n",
            "Step: 190, Reward mean: 208.73983574655222, Reward std: 230.17930400652472, Episodes: 3382, Steps: 432911\n",
            "Step: 200, Reward mean: 595.6634628938591, Reward std: 200.60491079222004, Episodes: 3467, Steps: 455881\n",
            "Step: 210, Reward mean: 207.48802012035995, Reward std: 107.72524018328731, Episodes: 3517, Steps: 482576\n",
            "Step: 220, Reward mean: 113.42219964156102, Reward std: 59.97077317600735, Episodes: 3594, Steps: 506438\n",
            "Step: 230, Reward mean: 344.0626761120541, Reward std: 224.59787396652186, Episodes: 3667, Steps: 529989\n",
            "Step: 240, Reward mean: 108.27313925677007, Reward std: 47.37286013552991, Episodes: 3748, Steps: 554205\n",
            "Step: 250, Reward mean: 203.4277855169476, Reward std: 119.5301270182288, Episodes: 3827, Steps: 576731\n",
            "Step: 260, Reward mean: 305.187877461772, Reward std: 211.77455411937922, Episodes: 3910, Steps: 600429\n",
            "Step: 270, Reward mean: 179.6295910594401, Reward std: 139.8013116658246, Episodes: 3984, Steps: 624638\n",
            "Step: 280, Reward mean: 243.99934372811896, Reward std: 195.9929670009272, Episodes: 4079, Steps: 647807\n",
            "Step: 290, Reward mean: 119.85299416850437, Reward std: 77.68509517882202, Episodes: 4157, Steps: 670482\n",
            "Step: 300, Reward mean: 522.4052583863241, Reward std: 132.0139281295938, Episodes: 4268, Steps: 692252\n",
            "Step: 310, Reward mean: 235.62500927112896, Reward std: 171.14687912799423, Episodes: 4346, Steps: 714256\n",
            "Step: 320, Reward mean: 428.5963569604618, Reward std: 213.53226384315724, Episodes: 4459, Steps: 736865\n",
            "Step: 330, Reward mean: 167.14549685842417, Reward std: 42.09725374817456, Episodes: 4548, Steps: 760427\n",
            "Step: 340, Reward mean: 350.6797308136508, Reward std: 214.2838898148381, Episodes: 4637, Steps: 784114\n",
            "Step: 350, Reward mean: 197.3945986152446, Reward std: 44.989171944222406, Episodes: 4712, Steps: 807009\n",
            "Step: 360, Reward mean: 144.05210636711766, Reward std: 66.3040080226711, Episodes: 4793, Steps: 829569\n",
            "Step: 370, Reward mean: 551.2310230083486, Reward std: 266.44411998726514, Episodes: 4876, Steps: 851645\n",
            "Step: 380, Reward mean: 314.2729952344441, Reward std: 273.06861942776595, Episodes: 4964, Steps: 874316\n",
            "Step: 390, Reward mean: 176.21881963040912, Reward std: 105.53875837571132, Episodes: 5056, Steps: 896191\n",
            "Step: 400, Reward mean: 273.7403320525308, Reward std: 256.7402124467698, Episodes: 5141, Steps: 919061\n",
            "Step: 410, Reward mean: 225.49693145651986, Reward std: 99.51068725754146, Episodes: 5226, Steps: 941218\n",
            "Step: 420, Reward mean: 201.46401422512525, Reward std: 120.43047902684957, Episodes: 5308, Steps: 963646\n",
            "Step: 430, Reward mean: 329.0170186511863, Reward std: 185.99135119209888, Episodes: 5392, Steps: 985748\n",
            "Step: 440, Reward mean: 274.2423679608995, Reward std: 97.82581046071343, Episodes: 5489, Steps: 1007651\n",
            "Step: 450, Reward mean: 204.63154670974328, Reward std: 52.712900085259164, Episodes: 5579, Steps: 1029058\n",
            "Step: 460, Reward mean: 314.98030773692744, Reward std: 176.46351648963503, Episodes: 5668, Steps: 1051904\n",
            "Step: 470, Reward mean: 530.0263715440944, Reward std: 354.6399931129089, Episodes: 5736, Steps: 1074996\n",
            "Step: 480, Reward mean: 568.3342636494345, Reward std: 255.62905412851643, Episodes: 5801, Steps: 1097364\n",
            "Step: 490, Reward mean: 404.60954956512626, Reward std: 404.7601280266871, Episodes: 5856, Steps: 1121489\n",
            "Step: 500, Reward mean: 697.3002302689666, Reward std: 200.05908486261623, Episodes: 5909, Steps: 1146375\n",
            "Step: 510, Reward mean: 613.6545111563872, Reward std: 266.23556620513284, Episodes: 5966, Steps: 1170407\n",
            "Step: 520, Reward mean: 496.04475452297874, Reward std: 351.28214241944715, Episodes: 6019, Steps: 1195491\n",
            "Step: 530, Reward mean: 642.7181313366273, Reward std: 305.51954861168673, Episodes: 6064, Steps: 1221800\n",
            "Step: 540, Reward mean: 886.5969491927666, Reward std: 432.1853406209651, Episodes: 6108, Steps: 1250627\n",
            "Step: 550, Reward mean: 899.099658117901, Reward std: 463.52652960374854, Episodes: 6154, Steps: 1280225\n",
            "Step: 560, Reward mean: 484.9778132458117, Reward std: 440.8218682425693, Episodes: 6199, Steps: 1306457\n",
            "Step: 570, Reward mean: 609.971776455976, Reward std: 445.12198938928503, Episodes: 6241, Steps: 1332700\n",
            "Step: 580, Reward mean: 626.9157257876177, Reward std: 251.1754550080216, Episodes: 6291, Steps: 1357333\n",
            "Step: 590, Reward mean: 936.6960349907004, Reward std: 395.79327333532495, Episodes: 6336, Steps: 1382728\n",
            "Step: 600, Reward mean: 774.155580933051, Reward std: 433.072513457535, Episodes: 6388, Steps: 1407839\n",
            "Step: 610, Reward mean: 922.3843388931591, Reward std: 480.2889432849429, Episodes: 6430, Steps: 1435898\n",
            "Step: 620, Reward mean: 513.0395681583361, Reward std: 359.8224592574543, Episodes: 6473, Steps: 1462394\n",
            "Step: 630, Reward mean: 822.8755648226643, Reward std: 531.0382307926277, Episodes: 6520, Steps: 1490028\n",
            "Step: 640, Reward mean: 996.4701886541704, Reward std: 509.84704836714087, Episodes: 6565, Steps: 1516800\n",
            "Step: 650, Reward mean: 1313.5097592892193, Reward std: 390.442729964629, Episodes: 6608, Steps: 1545373\n",
            "Step: 660, Reward mean: 609.0745810658179, Reward std: 484.7245094056825, Episodes: 6657, Steps: 1570747\n",
            "Step: 670, Reward mean: 895.259575583814, Reward std: 682.2565548893581, Episodes: 6702, Steps: 1598393\n",
            "Step: 680, Reward mean: 790.5422757711224, Reward std: 544.1579128632736, Episodes: 6753, Steps: 1626891\n",
            "Step: 690, Reward mean: 760.4214043118272, Reward std: 524.8202262040087, Episodes: 6812, Steps: 1650953\n",
            "Step: 700, Reward mean: 665.6703626427496, Reward std: 402.1418724613128, Episodes: 6862, Steps: 1678194\n",
            "Step: 710, Reward mean: 597.1355459041978, Reward std: 459.71041761194505, Episodes: 6907, Steps: 1705756\n",
            "Step: 720, Reward mean: 258.88838224777027, Reward std: 167.68570660494603, Episodes: 6949, Steps: 1734825\n",
            "Step: 730, Reward mean: 525.196388544454, Reward std: 454.239436638046, Episodes: 6994, Steps: 1763921\n",
            "Step: 740, Reward mean: 1246.4146722351365, Reward std: 583.5431239264751, Episodes: 7039, Steps: 1790474\n",
            "Step: 750, Reward mean: 1351.365425916421, Reward std: 275.2884902098785, Episodes: 7079, Steps: 1820799\n",
            "Step: 760, Reward mean: 1335.0482841343658, Reward std: 328.0422591957684, Episodes: 7120, Steps: 1848443\n",
            "Step: 770, Reward mean: 1270.693111931964, Reward std: 474.2756640363323, Episodes: 7162, Steps: 1877519\n",
            "Step: 780, Reward mean: 1267.5853893779954, Reward std: 423.7312685142692, Episodes: 7203, Steps: 1910297\n",
            "Step: 790, Reward mean: 348.58361748952456, Reward std: 318.2118485422654, Episodes: 7254, Steps: 1934051\n",
            "Step: 800, Reward mean: 190.6793687691798, Reward std: 221.81014458095157, Episodes: 7339, Steps: 1956932\n",
            "Step: 810, Reward mean: 537.4458447417337, Reward std: 284.2064100496299, Episodes: 7393, Steps: 1981301\n",
            "Step: 820, Reward mean: 985.3965576649659, Reward std: 530.6589403371056, Episodes: 7440, Steps: 2005628\n",
            "Step: 830, Reward mean: 951.1358872655521, Reward std: 599.4995196073224, Episodes: 7487, Steps: 2032416\n",
            "Step: 840, Reward mean: 929.6522920232812, Reward std: 371.7084888596542, Episodes: 7531, Steps: 2059565\n",
            "Step: 850, Reward mean: 1374.9119332169116, Reward std: 363.022109767258, Episodes: 7575, Steps: 2087624\n",
            "Step: 860, Reward mean: 1203.3461317920442, Reward std: 482.4135649817535, Episodes: 7619, Steps: 2119713\n",
            "Step: 870, Reward mean: 1399.2167386060864, Reward std: 211.62636381857217, Episodes: 7660, Steps: 2148619\n",
            "Step: 880, Reward mean: 1263.3075429068485, Reward std: 408.31659966764073, Episodes: 7702, Steps: 2180839\n",
            "Step: 890, Reward mean: 1467.059413066951, Reward std: 277.07029858522384, Episodes: 7742, Steps: 2214543\n",
            "Step: 900, Reward mean: 1318.5311789611533, Reward std: 410.23416727304556, Episodes: 7783, Steps: 2246334\n",
            "Step: 910, Reward mean: 1193.0218989044072, Reward std: 344.69905964623575, Episodes: 7823, Steps: 2281502\n",
            "Step: 920, Reward mean: 1402.1180695368002, Reward std: 417.85580554433125, Episodes: 7864, Steps: 2313016\n",
            "Step: 930, Reward mean: 1438.292656883441, Reward std: 376.6744997952038, Episodes: 7906, Steps: 2345911\n",
            "Step: 940, Reward mean: 1041.1763966124895, Reward std: 630.9481311423745, Episodes: 7947, Steps: 2380099\n",
            "Step: 950, Reward mean: 834.4115145665348, Reward std: 687.9218299236139, Episodes: 7991, Steps: 2405533\n",
            "Step: 960, Reward mean: 1315.260452352427, Reward std: 469.7816390602305, Episodes: 8034, Steps: 2435410\n",
            "Step: 970, Reward mean: 1224.74392433609, Reward std: 611.1603618164683, Episodes: 8078, Steps: 2464465\n",
            "Step: 980, Reward mean: 784.9966069859718, Reward std: 706.0066925877086, Episodes: 8122, Steps: 2491387\n",
            "Step: 990, Reward mean: 1069.2947254964627, Reward std: 574.1266137714064, Episodes: 8165, Steps: 2516765\n",
            "Step: 1000, Reward mean: 1285.12618149318, Reward std: 648.4597530730524, Episodes: 8207, Steps: 2543845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qszJQ4vOAEmF",
        "outputId": "563e3936-8e29-44c3-e0cf-fadbcd34bb82"
      },
      "source": [
        "!zip task2_answer_2.zip train.py agent.py agent.pt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: train.py (deflated 69%)\n",
            "  adding: agent.py (deflated 50%)\n",
            "  adding: agent.pkl (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phw9mLJDEQQ-"
      },
      "source": [
        "!cp task2_answer_2.zip /content/drive/MyDrive"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glSjTg4pEQrm",
        "outputId": "207dc7fe-90b7-47db-836c-e8989bd3faa8"
      },
      "source": [
        "%mv best_agent.pt agent.pt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'best_agent.pkl': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtb1SjQEVn8",
        "outputId": "6446f5df-df32-4f96-cbe8-cb51fc641b5c"
      },
      "source": [
        "!zip task2_answer_3.zip train.py agent.py agent.pt"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: train.py (deflated 69%)\n",
            "  adding: agent.py (deflated 50%)\n",
            "  adding: agent.pkl (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNzIhxugEVbX"
      },
      "source": [
        "!cp task2_answer_3.zip /content/drive/MyDrive"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIJixFCEEVEa",
        "outputId": "838f9d91-d29e-4f78-8f8b-de06e6bdc312"
      },
      "source": [
        "# mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# copy it there\n",
        "# !cp example.txt /content/drive/MyDrive"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYP9EKCZEt5r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpX9PrCcEiG0"
      },
      "source": [
        "!cp /content/drive/MyDrive/task2_answer_2.zip ."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcdxmXlIEq3V",
        "outputId": "cbdabd95-d88f-4730-e23e-cd7b3d3a09f2"
      },
      "source": [
        "!unzip task2_answer_2.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  task2_answer_2.zip\n",
            "replace train.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.py                \n",
            "replace agent.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: agent.py                \n",
            "  inflating: agent.pkl               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qOynGIyE4J0"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adNRDjddEBjO"
      },
      "source": [
        "device = torch.device(\n",
        "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        )\n",
        "# model = torch.load(\"agent.pkl\").to(device)\n",
        "\n",
        "model = Actor(\n",
        "        state_dim=22,\n",
        "        action_dim=6,\n",
        "        device=device)\n",
        "model.load_state_dict(torch.load('agent.pt'))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgf3N8h8FPnn"
      },
      "source": [
        "state = [-1.35127199e-03,  0.00000000e+00,  1.00000000e+00,\n",
        "         5.15795685e-02,  0.00000000e+00, -6.56939447e-02,\n",
        "        -0.00000000e+00,  3.00311693e-03,  1.03054857e+00,\n",
        "        -7.01289624e-02,  9.64730918e-01,  2.24469811e-01,\n",
        "        -2.09774505e-02,  1.41997680e-01,  1.03643513e+00,\n",
        "         4.44089216e-17,  1.05073476e+00,  1.76783204e-02,\n",
        "         2.64076665e-02,  2.72563666e-01,  0.00000000e+00,\n",
        "         0.00000000e+00]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvBOxQZwFEvF"
      },
      "source": [
        "state = torch.tensor(np.array(state)).float().to(device)\n",
        "action, _, _ = model.act(state)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4yqxJeDFEeL",
        "outputId": "2d0f7b72-11d4-4bf1-dc00-f7cfc9a19ca8"
      },
      "source": [
        "action"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5978, -0.9993, -0.9986, -0.5075, -0.8375,  0.5366], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yHGN2DZEBUe",
        "outputId": "f1d5437c-d0ad-4ef3-df09-34edc53148c2"
      },
      "source": [
        "action.cpu().numpy()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.5977862, -0.9993487, -0.9985774, -0.507509 , -0.837531 ,\n",
              "        0.5366077], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyd1d4BuKN2e",
        "outputId": "1e3d5c94-c653-4a19-d916-e9e5e76224ad"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    }
  ]
}